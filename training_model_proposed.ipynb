{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training the proposed network"
      ],
      "metadata": {
        "id": "z8y-R06uSFUP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CXEf6EnP21n",
        "outputId": "61b32e7a-e591-4085-a98a-0e073f3952ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mmcv==1.7.1\n",
            "  Downloading mmcv-1.7.1.tar.gz (605 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.4/605.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from mmcv==1.7.1)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv==1.7.1) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv==1.7.1) (23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv==1.7.1) (8.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv==1.7.1) (6.0)\n",
            "Collecting yapf (from mmcv==1.7.1)\n",
            "  Downloading yapf-0.40.0-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata>=6.6.0 (from yapf->mmcv==1.7.1)\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Collecting platformdirs>=3.5.1 (from yapf->mmcv==1.7.1)\n",
            "  Downloading platformdirs-3.5.3-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==1.7.1) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv==1.7.1) (3.15.0)\n",
            "Building wheels for collected packages: mmcv\n",
            "  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv: filename=mmcv-1.7.1-py2.py3-none-any.whl size=930716 sha256=4b95f41570fab1c84de55c0a647292aae49b53ae750720ea1302251a4f1d93f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/f9/e3/7e8ab9b98ee9e91fcb677bea6a1ca23b755ddf87a982216acf\n",
            "Successfully built mmcv\n",
            "Installing collected packages: addict, platformdirs, importlib-metadata, yapf, mmcv\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 3.3.0\n",
            "    Uninstalling platformdirs-3.3.0:\n",
            "      Successfully uninstalled platformdirs-3.3.0\n",
            "Successfully installed addict-2.4.0 importlib-metadata-6.6.0 mmcv-1.7.1 platformdirs-3.5.3 yapf-0.40.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mmcv==1.7.1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing necessary libraries"
      ],
      "metadata": {
        "id": "_g0ur4Fj1gLf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC7kDo41fztO",
        "outputId": "30d9313e-334a-4c35-db94-cfc86faf3473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import math\n",
        "from mmcv.cnn import constant_init, kaiming_init\n",
        "from torch.nn import Module, Conv2d, Linear, MaxPool2d, ReLU, Flatten, BatchNorm2d, Dropout\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLyi9QRUf4Ec",
        "outputId": "8f181697-40ec-4de7-b64b-e13924dec67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "drive.mount ('/content/gdrive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vY_t6_ByN6-4"
      },
      "outputs": [],
      "source": [
        "## Hyper Parameters\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sbn0NpR53uH"
      },
      "source": [
        "## Loading the training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gq6wYdXvNrjH"
      },
      "outputs": [],
      "source": [
        "# Transformer to tensor\n",
        "transformer=transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6Yjn6WnZOIuy"
      },
      "outputs": [],
      "source": [
        "def load_dataset(d_path):\n",
        "    dataset_manual = torchvision.datasets.ImageFolder(d_path, transform=transformer)\n",
        "    print(\"Follwing classes are there : \\n\",dataset_manual.classes)\n",
        "    train_loader_manual = torch.utils.data.DataLoader(dataset_manual)\n",
        "    return train_loader_manual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnlOBm-jCAJd"
      },
      "source": [
        "Loading the dataset from Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pWA5aoZNyNcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8acc3e3c-9092-44ea-9dbe-650e6d083a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Follwing classes are there : \n",
            " ['Cercospora', 'Healthy', 'Miner', 'Phoma', 'Rust']\n",
            "Follwing classes are there : \n",
            " ['Cercospora', 'Healthy', 'Miner', 'Phoma', 'Rust']\n"
          ]
        }
      ],
      "source": [
        "train_dataset = load_dataset('/content/gdrive/MyDrive/Dataset/training_dataset')\n",
        "val_dataset = load_dataset('/content/gdrive/MyDrive/Dataset/validation_dataset')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=train_dataset.dataset\n",
        "val_dataset=val_dataset.dataset"
      ],
      "metadata": {
        "id": "mcLq_dIvfiJv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GzvJ0uxYD0a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ada2a1-b9d8-41c5-c356-fe82ed8433e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f34b8375e50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HvLNzeEQvz8K"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_1mkBpgvEFY7"
      },
      "outputs": [],
      "source": [
        "train_count = (len(train_dataset))\n",
        "val_count = len(val_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZDCxH0CxvxMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788f6dc5-f950-48cf-aab1-ff2d28827eb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set- 5020 images in 157 batches\n",
            "Validation Set - 2500 images in 79 batches\n"
          ]
        }
      ],
      "source": [
        "print('Train Set- ' + str(len(train_dataset)) + ' images in ' + str(len(train_loader)) +' batches')\n",
        "print('Validation Set - ' + str(len(val_dataset)) + ' images in ' + str(len(val_loader)) + ' batches')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JFBxt8Avg0zK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd65adfe-9229-4ccb-b1ab-4eda32d840c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch dimensions: torch.Size([32, 3, 256, 256])\n",
            "Image label dimensions: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "for images, labels in train_loader:\n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cb662bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913718ac-3d17-44f3-efb0-f5376028629e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 4, 2, 4, 2, 1, 1, 1, 4, 0, 2, 1, 2, 1, 3, 4, 0, 1, 1, 0, 4, 4, 4, 0,\n",
            "        2, 4, 3, 2, 3, 3, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "for images, labels in train_loader:\n",
        "    print (labels)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbs8qRxx5y6k"
      },
      "source": [
        "## Building the Proposed Network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "z1DAepmZ51Fz"
      },
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(nn.Module): #Implementing the Multi-head attention module\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        dk = query.size()[1]\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(dk)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attention = F.softmax(scores, dim=-1)\n",
        "        return torch.matmul(attention, value)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, in_channels, head_num, bias=True, activation=nn.ReLU()):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        if in_channels % head_num != 0:\n",
        "            raise ValueError('`in_channels`({}) should be divisible by `head_num`({})'.format(in_channels, head_num))\n",
        "        self.in_channels = in_channels\n",
        "        self.head_num = head_num\n",
        "        self.activation = activation\n",
        "        self.bias = bias\n",
        "        self.linear_q = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=bias)\n",
        "        self.linear_k = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=bias)\n",
        "        self.linear_v = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=bias)\n",
        "        self.linear_o = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=bias)\n",
        "    def forward(self, x, mask=None):\n",
        "        q, k, v = self.linear_q(x), self.linear_k(x), self.linear_v(x)\n",
        "        if self.activation is not None:\n",
        "            q = self.activation(q)\n",
        "            k = self.activation(k)\n",
        "            v = self.activation(v)\n",
        "        q, k, v = self._reshape_to_batches(q), self._reshape_to_batches(k), self._reshape_to_batches(v)\n",
        "        if mask is not None:\n",
        "            mask = mask.repeat(self.head_num, 1, 1, 1)\n",
        "        y = ScaledDotProductAttention()(q, k, v, mask)\n",
        "        y = self._reshape_from_batches(y)\n",
        "        y = self.linear_o(y)\n",
        "        if self.activation is not None:\n",
        "            y = self.activation(y)\n",
        "        return y\n",
        "\n",
        "    def _reshape_to_batches(self, x):\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        sub_channels = channels // self.head_num\n",
        "        return x.reshape(batch_size, self.head_num, sub_channels, height, width)\\\n",
        "                .permute(0, 2, 1, 3, 4)\\\n",
        "                .reshape(batch_size * self.head_num, sub_channels, height, width)\n",
        "\n",
        "    def _reshape_from_batches(self, x):\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        batch_size //= self.head_num\n",
        "        out_channels = channels * self.head_num\n",
        "        return x.reshape(batch_size, self.head_num, channels, height, width)\\\n",
        "                .permute(0, 2, 1, 3, 4)\\\n",
        "                .reshape(batch_size, out_channels, height, width)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ERiXgdRBPR0k"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module): #Convolutional + Relu + BatchNorm layer\n",
        "    def __init__(self, in_channels,out_channels,kernel_size, **kwargs):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.simple_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size = kernel_size, **kwargs),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        )\n",
        "    def forward(self, xb):\n",
        "        return self.simple_conv(xb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LypOb4OlPRyD"
      },
      "outputs": [],
      "source": [
        "class ConvWithMaxDrop(nn.Module): #Convolutional + Relu + BatchNorm + MaxPool + Dropout\n",
        "    def __init__(self, in_channels,out_channels,kernel_size):\n",
        "        super(ConvWithMaxDrop, self).__init__()\n",
        "        self.conv_maxp_drop = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size = kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            nn.Dropout(0.7),\n",
        "\n",
        "        )\n",
        "    def forward(self, xb):\n",
        "      return self.conv_maxp_drop(xb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mxNpiNqrPRtZ"
      },
      "outputs": [],
      "source": [
        "class InceptionBlock(nn.Module): #Inception module\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_1x1,\n",
        "        red_3x3,\n",
        "        out_3x3,\n",
        "        red_5x5,\n",
        "        out_5x5,\n",
        "        out_pool,\n",
        "    ):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "        self.branch1 = ConvBlock(in_channels, out_1x1, kernel_size=1)\n",
        "        self.branch2 = nn.Sequential(\n",
        "            ConvBlock(in_channels, red_3x3, kernel_size=1, padding=0),\n",
        "            ConvBlock(red_3x3, out_3x3, kernel_size=3, padding=1),\n",
        "        )\n",
        "        self.branch3 = nn.Sequential(\n",
        "            ConvBlock(in_channels, red_5x5, kernel_size=1),\n",
        "            ConvBlock(red_5x5, out_5x5, kernel_size=5, padding=2),\n",
        "        )\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
        "            ConvBlock(in_channels, out_pool, kernel_size=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branches = (self.branch1, self.branch2, self.branch3, self.branch4)\n",
        "        return torch.cat([branch(x) for branch in branches], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "k0dbZxvuPRqo"
      },
      "outputs": [],
      "source": [
        "def last_zero_init(m): # Global Context block\n",
        "    if isinstance(m, nn.Sequential):\n",
        "        constant_init(m[-1], val=0)\n",
        "    else:\n",
        "        constant_init(m, val=0)\n",
        "\n",
        "class ContextBlock(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 inplanes,\n",
        "                 ratio,\n",
        "                 pooling_type='att',\n",
        "                 fusion_types=('channel_add', )):\n",
        "        super(ContextBlock, self).__init__()\n",
        "        assert pooling_type in ['avg', 'att']\n",
        "        assert isinstance(fusion_types, (list, tuple))\n",
        "        valid_fusion_types = ['channel_add', 'channel_mul']\n",
        "        assert all([f in valid_fusion_types for f in fusion_types])\n",
        "        assert len(fusion_types) > 0, 'at least one fusion should be used'\n",
        "        self.inplanes = inplanes\n",
        "        self.ratio = ratio\n",
        "        self.planes = int(inplanes * ratio)\n",
        "        self.pooling_type = pooling_type\n",
        "        self.fusion_types = fusion_types\n",
        "        if pooling_type == 'att':\n",
        "            self.conv_mask = nn.Conv2d(inplanes, 1, kernel_size=1)\n",
        "            self.softmax = nn.Softmax(dim=2)\n",
        "        else:\n",
        "            self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        if 'channel_add' in fusion_types:\n",
        "            self.channel_add_conv = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, self.planes, kernel_size=1),\n",
        "                nn.LayerNorm([self.planes, 1, 1]),\n",
        "                nn.ReLU(inplace=True),  # yapf: disable\n",
        "                nn.Conv2d(self.planes, self.inplanes, kernel_size=1))\n",
        "        else:\n",
        "            self.channel_add_conv = None\n",
        "        if 'channel_mul' in fusion_types:\n",
        "            self.channel_mul_conv = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, self.planes, kernel_size=1),\n",
        "                nn.LayerNorm([self.planes, 1, 1]),\n",
        "                nn.ReLU(inplace=True),  # yapf: disable\n",
        "                nn.Conv2d(self.planes, self.inplanes, kernel_size=1))\n",
        "        else:\n",
        "            self.channel_mul_conv = None\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        if self.pooling_type == 'att':\n",
        "            kaiming_init(self.conv_mask, mode='fan_in')\n",
        "            self.conv_mask.inited = True\n",
        "\n",
        "        if self.channel_add_conv is not None:\n",
        "            last_zero_init(self.channel_add_conv)\n",
        "        if self.channel_mul_conv is not None:\n",
        "            last_zero_init(self.channel_mul_conv)\n",
        "\n",
        "    def spatial_pool(self, x):\n",
        "        batch, channel, height, width = x.size()\n",
        "        if self.pooling_type == 'att':\n",
        "            input_x = x\n",
        "            # [N, C, H * W]\n",
        "            input_x = input_x.view(batch, channel, height * width)\n",
        "            # [N, 1, C, H * W]\n",
        "            input_x = input_x.unsqueeze(1)\n",
        "            # [N, 1, H, W]\n",
        "            context_mask = self.conv_mask(x)\n",
        "            # [N, 1, H * W]\n",
        "            context_mask = context_mask.view(batch, 1, height * width)\n",
        "            # [N, 1, H * W]\n",
        "            context_mask = self.softmax(context_mask)\n",
        "            # [N, 1, H * W, 1]\n",
        "            context_mask = context_mask.unsqueeze(-1)\n",
        "            # [N, 1, C, 1]\n",
        "            context = torch.matmul(input_x, context_mask)\n",
        "            # [N, C, 1, 1]\n",
        "            context = context.view(batch, channel, 1, 1)\n",
        "        else:\n",
        "            # [N, C, 1, 1]\n",
        "            context = self.avg_pool(x)\n",
        "\n",
        "        return context\n",
        "\n",
        "    def forward(self, x):\n",
        "        # [N, C, 1, 1]\n",
        "        context = self.spatial_pool(x)\n",
        "\n",
        "        out = x\n",
        "        if self.channel_mul_conv is not None:\n",
        "            # [N, C, 1, 1]\n",
        "            channel_mul_term = torch.sigmoid(self.channel_mul_conv(context))\n",
        "            out = out * channel_mul_term\n",
        "        if self.channel_add_conv is not None:\n",
        "            # [N, C, 1, 1]\n",
        "            channel_add_term = self.channel_add_conv(context)\n",
        "            out = out + channel_add_term\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vfQh-nguPRoA"
      },
      "outputs": [],
      "source": [
        "class ProposedModel(nn.Module):  # Building the proposed network architecture\n",
        "    def __init__(self, aux_logits=True, num_classes=5):\n",
        "      super(ProposedModel,self).__init__()\n",
        "      self.aux_logits = aux_logits\n",
        "\n",
        "      self.conv1 = ConvBlock(in_channels=3, out_channels=8, kernel_size=3)\n",
        "\n",
        "      self.inception1 = InceptionBlock(in_channels=8, out_1x1=8, red_3x3=8, out_3x3=8, red_5x5=8, out_5x5=8, out_pool=8) #Inception module\n",
        "\n",
        "      self.conv2 = ConvBlock(in_channels=32, out_channels=64, kernel_size=3)\n",
        "\n",
        "      self.inception2 = InceptionBlock(in_channels=64, out_1x1=32, red_3x3=32, out_3x3=32, red_5x5=32, out_5x5=32, out_pool=32) # second Inception module\n",
        "\n",
        "      self.conv3 = ConvWithMaxDrop(in_channels=128, out_channels=192, kernel_size=3)\n",
        "\n",
        "      self.conv4 = ConvBlock(in_channels=192, out_channels=160, kernel_size=3)\n",
        "\n",
        "      self.gcblock = ContextBlock(inplanes=160, ratio=8) # Global Context block\n",
        "\n",
        "      self.conv5 = ConvWithMaxDrop(in_channels=160, out_channels=80, kernel_size=3)\n",
        "\n",
        "      self.conv6 = ConvBlock(in_channels=80, out_channels=64, kernel_size=3)\n",
        "\n",
        "      self.multi_head = MultiHeadAttention(in_channels=64, head_num=4) # Multi-head Attention module\n",
        "\n",
        "      self.conv7 = ConvWithMaxDrop(in_channels=64, out_channels=32, kernel_size=3)\n",
        "\n",
        "      self.fc1 = nn.Linear(25088, 256)\n",
        "\n",
        "\n",
        "      self.fc2 = nn.Linear(256, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv1(x)\n",
        "      x = self.inception1(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.inception2(x)\n",
        "      x = self.conv3(x)\n",
        "      x = self.conv4(x)\n",
        "      x = self.gcblock(x)\n",
        "      x = self.conv5(x)\n",
        "      x = self.conv6(x)\n",
        "      x = self.multi_head(x)\n",
        "      x = self.conv7(x)\n",
        "      x = x.reshape(x.shape[0], -1)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.softmax(self.fc2(x))\n",
        "      return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RpROOR567ZA"
      },
      "source": [
        "## Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_L7XGZBGDsjj"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UReKif_NCwnR",
        "outputId": "f1cb3e9c-a634-444a-90b9-f804705a9302"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "C8U-i6rz68Fr"
      },
      "outputs": [],
      "source": [
        "model = ProposedModel().to(device) #building the proposed network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDz32NvZ68el",
        "outputId": "40e0678f-0184-4a53-a37d-854a619d9917"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ProposedModel(\n",
              "  (conv1): ConvBlock(\n",
              "    (simple_conv): Sequential(\n",
              "      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (inception1): InceptionBlock(\n",
              "    (branch1): ConvBlock(\n",
              "      (simple_conv): Sequential(\n",
              "        (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): ReLU()\n",
              "        (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (simple_conv): Sequential(\n",
              "          (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "          (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (simple_conv): Sequential(\n",
              "          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU()\n",
              "          (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (simple_conv): Sequential(\n",
              "          (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "          (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (simple_conv): Sequential(\n",
              "          (0): Conv2d(8, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): ReLU()\n",
              "          (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): ConvBlock(\n",
              "        (simple_conv): Sequential(\n",
              "          (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "          (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv2): ConvBlock(\n",
              "    (simple_conv): Sequential(\n",
              "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (inception2): InceptionBlock(\n",
              "    (branch1): ConvBlock(\n",
              "      (simple_conv): Sequential(\n",
              "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): ReLU()\n",
              "        (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (simple_conv): Sequential(\n",
              "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (simple_conv): Sequential(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU()\n",
              "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): ConvBlock(\n",
              "        (simple_conv): Sequential(\n",
              "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): ConvBlock(\n",
              "        (simple_conv): Sequential(\n",
              "          (0): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): ReLU()\n",
              "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): ConvBlock(\n",
              "        (simple_conv): Sequential(\n",
              "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv3): ConvWithMaxDrop(\n",
              "    (conv_maxp_drop): Sequential(\n",
              "      (0): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (4): Dropout(p=0.7, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (conv4): ConvBlock(\n",
              "    (simple_conv): Sequential(\n",
              "      (0): Conv2d(192, 160, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (gcblock): ContextBlock(\n",
              "    (conv_mask): Conv2d(160, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (softmax): Softmax(dim=2)\n",
              "    (channel_add_conv): Sequential(\n",
              "      (0): Conv2d(160, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): LayerNorm((1280, 1, 1), eps=1e-05, elementwise_affine=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(1280, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (conv5): ConvWithMaxDrop(\n",
              "    (conv_maxp_drop): Sequential(\n",
              "      (0): Conv2d(160, 80, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (4): Dropout(p=0.7, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (conv6): ConvBlock(\n",
              "    (simple_conv): Sequential(\n",
              "      (0): Conv2d(80, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (multi_head): MultiHeadAttention(\n",
              "    (activation): ReLU()\n",
              "    (linear_q): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (linear_k): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (linear_v): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (linear_o): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (conv7): ConvWithMaxDrop(\n",
              "    (conv_maxp_drop): Sequential(\n",
              "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (4): Dropout(p=0.7, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=25088, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model.eval() # displays the proposed network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "v8PCODAUhF6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ef9b19-d5b3-4399-9a07-623e3dfbd9d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 8, 254, 254]             224\n",
            "              ReLU-2          [-1, 8, 254, 254]               0\n",
            "       BatchNorm2d-3          [-1, 8, 254, 254]              16\n",
            "         ConvBlock-4          [-1, 8, 254, 254]               0\n",
            "            Conv2d-5          [-1, 8, 254, 254]              72\n",
            "              ReLU-6          [-1, 8, 254, 254]               0\n",
            "       BatchNorm2d-7          [-1, 8, 254, 254]              16\n",
            "         ConvBlock-8          [-1, 8, 254, 254]               0\n",
            "            Conv2d-9          [-1, 8, 254, 254]              72\n",
            "             ReLU-10          [-1, 8, 254, 254]               0\n",
            "      BatchNorm2d-11          [-1, 8, 254, 254]              16\n",
            "        ConvBlock-12          [-1, 8, 254, 254]               0\n",
            "           Conv2d-13          [-1, 8, 254, 254]             584\n",
            "             ReLU-14          [-1, 8, 254, 254]               0\n",
            "      BatchNorm2d-15          [-1, 8, 254, 254]              16\n",
            "        ConvBlock-16          [-1, 8, 254, 254]               0\n",
            "           Conv2d-17          [-1, 8, 254, 254]              72\n",
            "             ReLU-18          [-1, 8, 254, 254]               0\n",
            "      BatchNorm2d-19          [-1, 8, 254, 254]              16\n",
            "        ConvBlock-20          [-1, 8, 254, 254]               0\n",
            "           Conv2d-21          [-1, 8, 254, 254]           1,608\n",
            "             ReLU-22          [-1, 8, 254, 254]               0\n",
            "      BatchNorm2d-23          [-1, 8, 254, 254]              16\n",
            "        ConvBlock-24          [-1, 8, 254, 254]               0\n",
            "        MaxPool2d-25          [-1, 8, 254, 254]               0\n",
            "           Conv2d-26          [-1, 8, 254, 254]              72\n",
            "             ReLU-27          [-1, 8, 254, 254]               0\n",
            "      BatchNorm2d-28          [-1, 8, 254, 254]              16\n",
            "        ConvBlock-29          [-1, 8, 254, 254]               0\n",
            "   InceptionBlock-30         [-1, 32, 254, 254]               0\n",
            "           Conv2d-31         [-1, 64, 252, 252]          18,496\n",
            "             ReLU-32         [-1, 64, 252, 252]               0\n",
            "      BatchNorm2d-33         [-1, 64, 252, 252]             128\n",
            "        ConvBlock-34         [-1, 64, 252, 252]               0\n",
            "           Conv2d-35         [-1, 32, 252, 252]           2,080\n",
            "             ReLU-36         [-1, 32, 252, 252]               0\n",
            "      BatchNorm2d-37         [-1, 32, 252, 252]              64\n",
            "        ConvBlock-38         [-1, 32, 252, 252]               0\n",
            "           Conv2d-39         [-1, 32, 252, 252]           2,080\n",
            "             ReLU-40         [-1, 32, 252, 252]               0\n",
            "      BatchNorm2d-41         [-1, 32, 252, 252]              64\n",
            "        ConvBlock-42         [-1, 32, 252, 252]               0\n",
            "           Conv2d-43         [-1, 32, 252, 252]           9,248\n",
            "             ReLU-44         [-1, 32, 252, 252]               0\n",
            "      BatchNorm2d-45         [-1, 32, 252, 252]              64\n",
            "        ConvBlock-46         [-1, 32, 252, 252]               0\n",
            "           Conv2d-47         [-1, 32, 252, 252]           2,080\n",
            "             ReLU-48         [-1, 32, 252, 252]               0\n",
            "      BatchNorm2d-49         [-1, 32, 252, 252]              64\n",
            "        ConvBlock-50         [-1, 32, 252, 252]               0\n",
            "           Conv2d-51         [-1, 32, 252, 252]          25,632\n",
            "             ReLU-52         [-1, 32, 252, 252]               0\n",
            "      BatchNorm2d-53         [-1, 32, 252, 252]              64\n",
            "        ConvBlock-54         [-1, 32, 252, 252]               0\n",
            "        MaxPool2d-55         [-1, 64, 252, 252]               0\n",
            "           Conv2d-56         [-1, 32, 252, 252]           2,080\n",
            "             ReLU-57         [-1, 32, 252, 252]               0\n",
            "      BatchNorm2d-58         [-1, 32, 252, 252]              64\n",
            "        ConvBlock-59         [-1, 32, 252, 252]               0\n",
            "   InceptionBlock-60        [-1, 128, 252, 252]               0\n",
            "           Conv2d-61        [-1, 192, 250, 250]         221,376\n",
            "             ReLU-62        [-1, 192, 250, 250]               0\n",
            "      BatchNorm2d-63        [-1, 192, 250, 250]             384\n",
            "        MaxPool2d-64        [-1, 192, 125, 125]               0\n",
            "          Dropout-65        [-1, 192, 125, 125]               0\n",
            "  ConvWithMaxDrop-66        [-1, 192, 125, 125]               0\n",
            "           Conv2d-67        [-1, 160, 123, 123]         276,640\n",
            "             ReLU-68        [-1, 160, 123, 123]               0\n",
            "      BatchNorm2d-69        [-1, 160, 123, 123]             320\n",
            "        ConvBlock-70        [-1, 160, 123, 123]               0\n",
            "           Conv2d-71          [-1, 1, 123, 123]             161\n",
            "          Softmax-72             [-1, 1, 15129]               0\n",
            "           Conv2d-73           [-1, 1280, 1, 1]         206,080\n",
            "        LayerNorm-74           [-1, 1280, 1, 1]           2,560\n",
            "             ReLU-75           [-1, 1280, 1, 1]               0\n",
            "           Conv2d-76            [-1, 160, 1, 1]         204,960\n",
            "     ContextBlock-77        [-1, 160, 123, 123]               0\n",
            "           Conv2d-78         [-1, 80, 121, 121]         115,280\n",
            "             ReLU-79         [-1, 80, 121, 121]               0\n",
            "      BatchNorm2d-80         [-1, 80, 121, 121]             160\n",
            "        MaxPool2d-81           [-1, 80, 60, 60]               0\n",
            "          Dropout-82           [-1, 80, 60, 60]               0\n",
            "  ConvWithMaxDrop-83           [-1, 80, 60, 60]               0\n",
            "           Conv2d-84           [-1, 64, 58, 58]          46,144\n",
            "             ReLU-85           [-1, 64, 58, 58]               0\n",
            "      BatchNorm2d-86           [-1, 64, 58, 58]             128\n",
            "        ConvBlock-87           [-1, 64, 58, 58]               0\n",
            "           Conv2d-88           [-1, 64, 58, 58]           4,160\n",
            "           Conv2d-89           [-1, 64, 58, 58]           4,160\n",
            "           Conv2d-90           [-1, 64, 58, 58]           4,160\n",
            "             ReLU-91           [-1, 64, 58, 58]               0\n",
            "             ReLU-92           [-1, 64, 58, 58]               0\n",
            "             ReLU-93           [-1, 64, 58, 58]               0\n",
            "           Conv2d-94           [-1, 64, 58, 58]           4,160\n",
            "             ReLU-95           [-1, 64, 58, 58]               0\n",
            "MultiHeadAttention-96           [-1, 64, 58, 58]               0\n",
            "           Conv2d-97           [-1, 32, 56, 56]          18,464\n",
            "             ReLU-98           [-1, 32, 56, 56]               0\n",
            "      BatchNorm2d-99           [-1, 32, 56, 56]              64\n",
            "       MaxPool2d-100           [-1, 32, 28, 28]               0\n",
            "         Dropout-101           [-1, 32, 28, 28]               0\n",
            " ConvWithMaxDrop-102           [-1, 32, 28, 28]               0\n",
            "          Linear-103                  [-1, 256]       6,422,784\n",
            "          Linear-104                    [-1, 5]           1,285\n",
            "================================================================\n",
            "Total params: 7,598,454\n",
            "Trainable params: 7,598,454\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 1212.65\n",
            "Params size (MB): 28.99\n",
            "Estimated Total Size (MB): 1242.38\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-94-eee12731ccd8>:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = F.softmax(self.fc2(x))\n"
          ]
        }
      ],
      "source": [
        "summary(model,(3,256,256)) #proposed model summary of input size (256,256,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8BKGQDR6eEO"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Cl1ucjrk6hnM"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10 # train for 10 epochs and save the model weights\n",
        "LEARNING_RATE = 0.0001\n",
        "WEIGHT_DECAY = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "w4kSwb9X6RUU"
      },
      "outputs": [],
      "source": [
        "optimizer=optim.Adam(model.parameters(),lr=LEARNING_RATE,weight_decay=WEIGHT_DECAY) #model compiled with optimization algorithm and loss function\n",
        "loss_function=nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZFnNVq-XaMsR"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/gdrive/MyDrive/proposed_model_size256_final.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### loading model weights and other checkpoint parameters"
      ],
      "metadata": {
        "id": "O_t21NG4frNP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6RYvnx9-aKV0"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "train_loss = checkpoint['train_loss']\n",
        "valid_loss = checkpoint['valid_loss']\n",
        "train_accuracy = checkpoint['train_accuracy']\n",
        "valid_accuracy = checkpoint['valid_accuracy']\n",
        "epochs_completed = checkpoint['epochs_completed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bSqbKxQcaP2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6410f91b-f7a9-4420-b003-b422ddb554f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05702671682687179 0.05770041843945335 0.9955312612416418 0.9866077561529295\n"
          ]
        }
      ],
      "source": [
        "print(train_loss, valid_loss, train_accuracy, valid_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VJnynaChlIE",
        "outputId": "18f8ae26-af06-4caf-f424-461f3f4039aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ],
      "source": [
        "print(epochs_completed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1oGjbkMZECIS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter # to store accuracy and loss values in tensorboard\n",
        "writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68JvRz64lFU2",
        "outputId": "498a1a5d-5bcc-4591-b1c1-ba709524c477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "aR0HSp_66cUY"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs): #model training\n",
        "\n",
        "    #Evaluation and training on training dataset\n",
        "    model.train()\n",
        "    print(\"\\nrunning epoch \" + str(epoch))\n",
        "    train_accuracy=0.0\n",
        "    train_loss=0.0\n",
        "\n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        print(\"running batch \" + str(i), end=\" \")\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs=model(images)\n",
        "\n",
        "        loss=loss_function(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "\n",
        "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "\n",
        "    train_accuracy=train_accuracy/train_count\n",
        "    train_loss=train_loss/train_count\n",
        "\n",
        "\n",
        "    # Evaluation on testing dataset\n",
        "    model.eval()\n",
        "\n",
        "    valid_accuracy = 0.0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    for i, (images,labels) in enumerate(val_loader):\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "          images=Variable(images.cuda())\n",
        "          labels=Variable(labels.cuda())\n",
        "\n",
        "        outputs=model(images)\n",
        "\n",
        "        loss = loss_function (outputs, labels)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        valid_accuracy += int(torch.sum(prediction == labels.data))\n",
        "\n",
        "        valid_loss+= loss.item()\n",
        "\n",
        "\n",
        "        valid_accuracy = valid_accuracy/val_count\n",
        "        valid_loss = valid_loss/val_count\n",
        "    writer.add_scalar(\"Training Loss/epoch\", train_loss, epoch)\n",
        "    writer.add_scalar(\"Validation Loss/epoch\", valid_loss, epoch)\n",
        "    writer.add_scalar(\"Training Accuracy/epoch\", train_accuracy, epoch)\n",
        "    writer.add_scalar(\"Validation Accuracy/epoch\", valid_accuracy, epoch)\n",
        "\n",
        "\n",
        "\n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'valid_loss': valid_loss,\n",
        "            'train_accuracy': train_accuracy,\n",
        "            'valid_accuracy': valid_accuracy,\n",
        "            'epochs_completed': epochs_completed + epoch + 1\n",
        "            }, PATH)\n",
        "\n",
        "    print('\\nEpoch: %d Train Loss: %.6f Train Accuracy: %.6f Validation Loss: %.6f  Validation Accuracy: %.6f' % (epoch, train_loss, train_accuracy, valid_loss, valid_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fPKi0_tEbOg"
      },
      "outputs": [],
      "source": [
        "writer.flush() #flushing the remaining stored values in writer object and closing the writer object\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorBoard"
      ],
      "metadata": {
        "id": "aJDA7ADTgXwM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8MU4sYiIrc-"
      },
      "outputs": [],
      "source": [
        "!pip install tensorboard #tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVG_aLPYNaJW"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFKnb5xCI-fO"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir runs #displays accuracy and loss vs epoch graphs in tensorboard"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}